## SVD (Singular Value Decomposition)

SVD — это представление матрицы в виде произведения трёх матриц: $U$, $S$, и $V^T$.

- **$U$** (левые сингулярные векторы): ортогональная матрица, столбцы — главные направления входного пространства.
- **$S$** (сингулярные значения): диагональная матрица, элементы которой показывают, насколько $A$ растягивает или сжимает данные вдоль соответствующих направлений.
- **$V^T$** (правые сингулярные векторы): ортогональная матрица, её строки (или столбцы до транспонирования) — главные оси в выходном пространстве.

### Интуиция за каждой матрицей

- **$U$:** находит главные направления входного пространства; столбцы — как повернуть данные для выявления самых выраженных паттернов.
- **$S$:** диагональные значения показывают силу растяжения/сжатия вдоль каждого направления.
- **$V^T$:** строки (или столбцы $V$) — главные оси исходных переменных после всех преобразований.

**Аналогия:**  
$V^T$ — начальный поворот,  
$S$ — растяжение/сжатие,  
$U$ — финальный поворот.

### Значение SVD

SVD используют для снижения размерности, сжатия данных, устойчивого решения систем линейных уравнений. Пример личного приложения — выделение фона на видео.

### SVD в PyTorch

В PyTorch используется функция `torch.linalg.svd()`.

**Параметры:**
- `input` — матрица для разложения.
- `full_matrices` (по умолчанию False) — полные или усечённые матрицы $U$ и $V^T$.
