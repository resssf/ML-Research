{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26c611e-2f23-45ef-8873-585e5402b6dd",
   "metadata": {},
   "source": [
    "# 02. PyTorch Tensors Tutorial\n",
    "\n",
    "**Goals:** get understadning how to work with tensors in PyTorch.\n",
    "\n",
    "**Source:** [PyTorch Docs Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "This notebook will provide examples and explanations of basic operations with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9332085b-5c82-4a99-939c-e1ef4f9867dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc46cb-e208-4943-ba66-0e8d21f2138a",
   "metadata": {},
   "source": [
    "## 1. Initialization of Tensors\n",
    "\n",
    "Tesors can be created in different ways: from data, from numpy, from another tensor, using random/constant value generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b8952f-83cb-4beb-aea5-ed3b7b92cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "x_np:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "x_ones\n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "x_rand\n",
      " tensor([[0.5829, 0.3514],\n",
      "        [0.5577, 0.7099]])\n",
      "zeros_tensor:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "ones_tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "rand_tensor:\n",
      " tensor([[0.4026, 0.7114, 0.9271],\n",
      "        [0.5106, 0.4982, 0.2899]])\n"
     ]
    }
   ],
   "source": [
    "# Initializating from data\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# From a numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# From another tensor (the same shape, but another data)\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the dataype of x_data\n",
    "\n",
    "# Using random/constant value generators\n",
    "shape = (2, 3,)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "rand_tensor = torch.rand(shape)\n",
    "\n",
    "print(\"x_data:\\n\", x_data)\n",
    "print(\"x_np:\\n\", x_np)\n",
    "print(\"x_ones\\n\", x_ones)\n",
    "print(\"x_rand\\n\", x_rand)\n",
    "print(\"zeros_tensor:\\n\", zeros_tensor)\n",
    "print(\"ones_tensor:\\n\", ones_tensor)\n",
    "print(\"rand_tensor:\\n\", rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d566b2-5c69-4017-82ad-ead055b1c1da",
   "metadata": {},
   "source": [
    "## 2. Attributes of a Tensor\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on whice they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effa09f9-76ef-49bd-8d64-9b05a97d7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([4, 5])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 5)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b47306-4251-40fe-b934-8bc8fdfa448f",
   "metadata": {},
   "source": [
    "## 3. Operations on Tensors\n",
    "\n",
    "A large number of operations - over 1200.\n",
    "From basic: arithmetic, linear algebra, matrix manipulation (transposing, inxdexing, slicing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3290cf7a-4908-470e-bb0b-698f0ac344c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1.])\n",
      "First column: tensor([1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1.])\n",
      "tensor([[  1.,   1., 404.],\n",
      "        [  1.,   1., 404.],\n",
      "        [  1.,   1., 404.]])\n",
      "tensor([[  1.,   1., 404.,   1.,   1., 404.,   1.,   1., 404.],\n",
      "        [  1.,   1., 404.,   1.,   1., 404.,   1.,   1., 404.],\n",
      "        [  1.,   1., 404.,   1.,   1., 404.,   1.,   1., 404.]])\n",
      "y1 (matmul):\n",
      " tensor([[163218., 163218., 163218.],\n",
      "        [163218., 163218., 163218.],\n",
      "        [163218., 163218., 163218.]])\n",
      "z1 (mul):\n",
      " tensor([[1.0000e+00, 1.0000e+00, 1.6322e+05],\n",
      "        [1.0000e+00, 1.0000e+00, 1.6322e+05],\n",
      "        [1.0000e+00, 1.0000e+00, 1.6322e+05]])\n"
     ]
    }
   ],
   "source": [
    "# Numpy-like indexing and slicing ( remainder: row, column)\n",
    "tensor = torch.ones(3, 3)\n",
    "\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\") # ... is equal to ':,' dim(Tensor)-1 \n",
    "\n",
    "tensor[:, 2] = 404 # Change the third column to 404\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "# Joining tensors\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "\n",
    "print(t1)\n",
    "\n",
    "\n",
    "# Arithmetic operations\n",
    "y1 = tensor @ tensor.T # Matrix multiplication\n",
    "z1 = tensor * tensor # Element-wise product\n",
    "\n",
    "print(\"y1 (matmul):\\n\", y1)\n",
    "print(\"z1 (mul):\\n\", z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed4538b-06bb-4326-88c1-e7e00fb2fc98",
   "metadata": {},
   "source": [
    "## 4. Bridge with NumPy\n",
    "\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memore locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d647ead-af3b-4bde-8958-a0eee53c6808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: tensor([1., 1., 1., 1., 1.])\n",
      "n1: [1. 1. 1. 1. 1.]\n",
      "n2: [1. 1. 1. 1. 1.]\n",
      "t2: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "After changing:\n",
      "t1: tensor([0., 0., 0., 0., 0.])\n",
      "n1: [0. 0. 0. 0. 0.]\n",
      "n2: [2. 2. 2. 2. 2.]\n",
      "t2: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "t1= torch.ones(5)\n",
    "n1 = t1.numpy()\n",
    "\n",
    "print(f\"t1: {t1}\")\n",
    "print(f\"n1: {n1}\")\n",
    "\n",
    "\n",
    "# NumPy array to Tensor\n",
    "n2 = np.ones(5)\n",
    "t2 = torch.from_numpy(n2)\n",
    "\n",
    "print(f\"n2: {n2}\")\n",
    "print(f\"t2: {t2}\")\n",
    "\n",
    "\n",
    "# A change in one reflects on the other.\n",
    "t1.add_(-1) # first pair\n",
    "np.add(n2, +1, out=n2) # second pair\n",
    "\n",
    "print(\"After changing:\")\n",
    "\n",
    "print(f\"t1: {t1}\")\n",
    "print(f\"n1: {n1}\")\n",
    "\n",
    "print(f\"n2: {n2}\")\n",
    "print(f\"t2: {t2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb791ba-55da-4b8f-9410-b32768d57478",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "By default, all tensors in PyTorch are created on the CPU. This is important because if you want to use an accelerator, such as a GPU, be sure to first transfer the tensors to that device using the $.to(<device>)$ method and then check its availability in the system. However, be careful because improper use may lead to errors or decreased performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657ca23-ee83-4b0a-a4b8-ea5151f3a2b6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- We learned how to work with Tensors.\n",
    "- Changes in one object automatically reflect in another if they are linked via memory.\n",
    "- This saves resources, but requires careful handling of inplace-operations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
